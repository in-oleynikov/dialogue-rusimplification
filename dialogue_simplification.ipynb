{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dialogue_simplification.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"162WPtkD1OEqLXC0YhVaSMWtE4CZaQ96K","authorship_tag":"ABX9TyMHLBmw4/iPLZOypS9XbkC6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZnZyJg9_kasj","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1616340064137,"user_tz":-180,"elapsed":34035,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"4e642565-5297-4f37-ca82-2b95d9d5eb99"},"source":["!pip install razdel\n","!pip3 install -r \"/content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt\"\n","!pip install rnnmorph\n","\n","!pip install git+https://github.com/huggingface/transformers\n","\n","!git clone https://github.com/feralvam/easse.git\n","%cd /content/easse/\n","!pip install .\n"],"execution_count":55,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (0.5.0)\n","Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n","\u001b[?25hCollecting datasets>=1.1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/43b396481a8298c6010afb93b3c1e71d4ba6f8c10797a7da8eb005e45081/datasets-1.5.0-py3-none-any.whl (192kB)\n","\u001b[K     |████████████████████████████████| 194kB 14.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 1)) (0.22.2.post1)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (3.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (1.1.5)\n","Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (4.41.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (0.70.11.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (0.3.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (2.23.0)\n","Collecting huggingface-hub<0.1.0\n","  Downloading https://files.pythonhosted.org/packages/af/07/bf95f398e6598202d878332280f36e589512174882536eb20d792532a57d/huggingface_hub-0.0.7-py3-none-any.whl\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (3.7.2)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/27/1c0b37c53a7852f1c190ba5039404d27b3ae96a55f48203a74259f8213c9/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |████████████████████████████████| 245kB 53.5MB/s \n","\u001b[?25hCollecting fsspec\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n","\u001b[K     |████████████████████████████████| 112kB 51.5MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 1)) (1.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (2018.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (1.24.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (3.0.12)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (3.4.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.1.3->-r /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification/requirements.txt (line 2)) (1.15.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=875d82c6256ac0767b2f4eb50707b15e7a3bcd1afc7898d36dfa3b468687345f\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: seqeval, huggingface-hub, xxhash, fsspec, datasets\n","Successfully installed datasets-1.5.0 fsspec-0.8.7 huggingface-hub-0.0.7 seqeval-1.2.2 xxhash-2.0.0\n","Requirement already satisfied: rnnmorph in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: russian-tagsets==0.6 in /usr/local/lib/python3.7/dist-packages (from rnnmorph) (0.6)\n","Requirement already satisfied: jsonpickle>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from rnnmorph) (2.0.0)\n","Requirement already satisfied: keras>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from rnnmorph) (2.4.3)\n","Requirement already satisfied: pymorphy2>=0.8 in /usr/local/lib/python3.7/dist-packages (from rnnmorph) (0.9.1)\n","Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from rnnmorph) (0.22.2.post1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from rnnmorph) (1.4.1)\n","Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from rnnmorph) (4.41.1)\n","Requirement already satisfied: tensorflow>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from rnnmorph) (2.4.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from rnnmorph) (1.19.5)\n","Requirement already satisfied: nltk>=3.2.5 in /usr/local/lib/python3.7/dist-packages (from rnnmorph) (3.4.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from jsonpickle>=0.9.4->rnnmorph) (3.7.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.6->rnnmorph) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.6->rnnmorph) (3.13)\n","Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.8->rnnmorph) (0.7.2)\n","Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.8->rnnmorph) (2.4.417127.4579844)\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.8->rnnmorph) (0.6.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.1->rnnmorph) (1.0.1)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (2.4.1)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (1.12)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (1.1.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (1.6.3)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (0.2.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (0.36.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (3.12.4)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (0.3.3)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (1.12.1)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (1.15.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (3.7.4.3)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (1.32.0)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (2.4.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (3.3.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (1.1.2)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.1.0->rnnmorph) (0.10.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle>=0.9.4->rnnmorph) (3.4.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (1.27.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (1.8.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (54.1.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (3.3.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (0.4.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (4.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (2020.12.5)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.1.0->rnnmorph) (3.1.0)\n","Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-jl63leo1\n","  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-jl63leo1\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied (use --upgrade to upgrade): transformers==4.5.0.dev0 from git+https://github.com/huggingface/transformers in /usr/local/lib/python3.7/dist-packages\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (0.0.43)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (2019.12.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (3.7.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (0.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (20.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0.dev0) (1.19.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0.dev0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0.dev0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0.dev0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0.dev0) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0.dev0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0.dev0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0.dev0) (1.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.0.dev0) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.0.dev0) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.0.dev0) (2.4.7)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.5.0.dev0-cp37-none-any.whl size=1972568 sha256=091e9ba912b36233f17aeb41ea127a3b6bd6fb13f327888ac348f20c38d0fbfc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-63jrm0hd/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n","Successfully built transformers\n","fatal: destination path 'easse' already exists and is not an empty directory.\n","/content/easse\n","Processing /content/easse\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (3.2.2)\n","Requirement already satisfied: nltk==3.4.3 in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (3.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (1.1.5)\n","Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (2.23.0)\n","Requirement already satisfied: sacrebleu>=1.4.13 in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (1.5.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (0.0.43)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (0.11.1)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (0.0)\n","Requirement already satisfied: stanfordnlp in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (0.2.0)\n","Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (4.41.1)\n","Requirement already satisfied: tupa>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (1.4.2)\n","Requirement already satisfied: yattag in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (1.14.0)\n","Requirement already satisfied: plotly>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (4.4.1)\n","Requirement already satisfied: bert_score in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (0.3.8)\n","Requirement already satisfied: ucca@ git+https://github.com/louismartin/ucca.git from git+https://github.com/louismartin/ucca.git in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (1.2.3)\n","Requirement already satisfied: tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git from git+https://github.com/facebookresearch/text-simplification-evaluation.git in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (1.0)\n","Requirement already satisfied: simalign@ git+https://github.com/cisnlp/simalign.git from git+https://github.com/cisnlp/simalign.git in /usr/local/lib/python3.7/dist-packages (from easse==0.2.4) (0.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->easse==0.2.4) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->easse==0.2.4) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->easse==0.2.4) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->easse==0.2.4) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.3->easse==0.2.4) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->easse==0.2.4) (2018.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->easse==0.2.4) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->easse==0.2.4) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->easse==0.2.4) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.21.0->easse==0.2.4) (2020.12.5)\n","Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.13->easse==0.2.4) (2.0.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses->easse==0.2.4) (2019.12.20)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->easse==0.2.4) (1.0.1)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->easse==0.2.4) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->easse==0.2.4) (0.22.2.post1)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from stanfordnlp->easse==0.2.4) (1.8.0+cu101)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanfordnlp->easse==0.2.4) (3.12.4)\n","Requirement already satisfied: logbook>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from tupa>=1.3.0->easse==0.2.4) (1.5.3)\n","Requirement already satisfied: dynet==2.1 in /usr/local/lib/python3.7/dist-packages (from tupa>=1.3.0->easse==0.2.4) (2.1)\n","Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from tupa>=1.3.0->easse==0.2.4) (0.29.22)\n","Requirement already satisfied: configargparse>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from tupa>=1.3.0->easse==0.2.4) (1.4)\n","Requirement already satisfied: semstr[amr]<1.3,>=1.2.2 in /usr/local/lib/python3.7/dist-packages (from tupa>=1.3.0->easse==0.2.4) (1.2.2)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.0.0->easse==0.2.4) (1.3.3)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from bert_score->easse==0.2.4) (4.5.0.dev0)\n","Requirement already satisfied: spacy==2.1.3 in /usr/local/lib/python3.7/dist-packages (from ucca@ git+https://github.com/louismartin/ucca.git->easse==0.2.4) (2.1.3)\n","Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git->easse==0.2.4) (3.1.14)\n","Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (from tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git->easse==0.2.4) (0.12.2)\n","Requirement already satisfied: networkx==2.4 in /usr/local/lib/python3.7/dist-packages (from simalign@ git+https://github.com/cisnlp/simalign.git->easse==0.2.4) (2.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->stanfordnlp->easse==0.2.4) (3.7.4.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->stanfordnlp->easse==0.2.4) (54.1.2)\n","Requirement already satisfied: penman==0.6.2; extra == \"amr\" in /usr/local/lib/python3.7/dist-packages (from semstr[amr]<1.3,>=1.2.2->tupa>=1.3.0->easse==0.2.4) (0.6.2)\n","Requirement already satisfied: pyspotlight==0.7.2; extra == \"amr\" in /usr/local/lib/python3.7/dist-packages (from semstr[amr]<1.3,>=1.2.2->tupa>=1.3.0->easse==0.2.4) (0.7.2)\n","Requirement already satisfied: smatch==1.0.1; extra == \"amr\" in /usr/local/lib/python3.7/dist-packages (from semstr[amr]<1.3,>=1.2.2->tupa>=1.3.0->easse==0.2.4) (1.0.1)\n","Requirement already satisfied: parsimonious==0.8.1; extra == \"amr\" in /usr/local/lib/python3.7/dist-packages (from semstr[amr]<1.3,>=1.2.2->tupa>=1.3.0->easse==0.2.4) (0.8.1)\n","Requirement already satisfied: word2number==1.1; extra == \"amr\" in /usr/local/lib/python3.7/dist-packages (from semstr[amr]<1.3,>=1.2.2->tupa>=1.3.0->easse==0.2.4) (1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (0.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (3.7.2)\n","Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->ucca@ git+https://github.com/louismartin/ucca.git->easse==0.2.4) (2.6.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->ucca@ git+https://github.com/louismartin/ucca.git->easse==0.2.4) (2.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->ucca@ git+https://github.com/louismartin/ucca.git->easse==0.2.4) (1.0.5)\n","Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->ucca@ git+https://github.com/louismartin/ucca.git->easse==0.2.4) (0.2.4)\n","Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->ucca@ git+https://github.com/louismartin/ucca.git->easse==0.2.4) (1.0.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->ucca@ git+https://github.com/louismartin/ucca.git->easse==0.2.4) (0.8.2)\n","Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->ucca@ git+https://github.com/louismartin/ucca.git->easse==0.2.4) (2.0.1)\n","Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->ucca@ git+https://github.com/louismartin/ucca.git->easse==0.2.4) (0.9.6)\n","Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.3->ucca@ git+https://github.com/louismartin/ucca.git->easse==0.2.4) (7.0.8)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git->easse==0.2.4) (4.0.5)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx==2.4->simalign@ git+https://github.com/cisnlp/simalign.git->easse==0.2.4) (4.4.2)\n","Requirement already satisfied: docopt>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from penman==0.6.2; extra == \"amr\"->semstr[amr]<1.3,>=1.2.2->tupa>=1.3.0->easse==0.2.4) (0.6.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=3.0.0->bert_score->easse==0.2.4) (3.4.1)\n","Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git->easse==0.2.4) (3.0.5)\n","Building wheels for collected packages: easse\n","  Building wheel for easse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for easse: filename=easse-0.2.4-cp37-none-any.whl size=8937227 sha256=82de4e56067b8790393227d0382f72edfe53701db60081b4b276f7d33760933f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_dmcx4jf/wheels/ca/07/fd/1757c0f0715621bb12ff9c6eb50591025c4be06a9ec1c5c445\n","Successfully built easse\n","Installing collected packages: easse\n","  Found existing installation: easse 0.2.4\n","    Uninstalling easse-0.2.4:\n","      Successfully uninstalled easse-0.2.4\n","Successfully installed easse-0.2.4\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["easse"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"xmmXc-X36ZCv"},"source":["## Loading data"]},{"cell_type":"code","metadata":{"id":"axXMDzfVOtBV","executionInfo":{"status":"ok","timestamp":1616338395163,"user_tz":-180,"elapsed":570,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["import pandas as pd\n","import numpy as np\n","import os\n","from tqdm import tqdm_notebook\n","from razdel import tokenize\n","\n","from rnnmorph.predictor import RNNMorphPredictor\n","from sklearn.model_selection import train_test_split\n","from easse.sari import corpus_sari\n","import json\n","PATH = '/content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification'"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"jbDKOx9uPH13","executionInfo":{"status":"ok","timestamp":1616341101217,"user_tz":-180,"elapsed":567,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["# Read the data\n","df = pd.read_csv(os.path.join(PATH,'dev_sents.csv'))\n","pd.set_option('display.max_colwidth', 150)\n","pd.set_option('display.width', 500)\n"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpyY3YsCPoqv","executionInfo":{"status":"ok","timestamp":1616338402148,"user_tz":-180,"elapsed":644,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"c970e3c5-b73b-4330-d7a9-b06742639016"},"source":["df.info()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 3406 entries, 0 to 3405\n","Data columns (total 3 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   Unnamed: 0     3406 non-null   int64 \n"," 1   INPUT:source   3406 non-null   object\n"," 2   OUTPUT:output  3406 non-null   object\n","dtypes: int64(1), object(2)\n","memory usage: 80.0+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"Kj8y0Jo941bY","executionInfo":{"status":"ok","timestamp":1616341083521,"user_tz":-180,"elapsed":593,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"34099be1-adb3-4b98-def5-ddd675003997"},"source":["df.head()"],"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>INPUT:source</th>\n","      <th>OUTPUT:output</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>14 декабря 1944 года рабочий посёлок Ички был переименован в рабочий посёлок Советский, после чего поселковый совет стал называться Советским.</td>\n","      <td>14 декабря 1944 года рабочий посёлок Ички переименован в Советский.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>1960 году была выпущена модель 172A. Изменения: хвостовое оперение и руль направления с обратной стреловидностью и крепления для поплавкового шасси.</td>\n","      <td>В 1960 году вышла модель 172А. Отличие в хвостовом оперении, в руле направления и в креплении шасси</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>1960 году была выпущена модель 172A. Изменения: хвостовое оперение и руль направления с обратной стреловидностью и крепления для поплавкового шасси.</td>\n","      <td>В выпущенной в 1960 году модель имела изменения в хвостовом оперении и руле направления</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>1960 году была выпущена модель 172A. Изменения: хвостовое оперение и руль направления с обратной стреловидностью и крепления для поплавкового шасси.</td>\n","      <td>Изменения: в хвосте и руле направления с обратной стреловидностью и крепления для поплавкового шасси.\\r\\n</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>1960 году была выпущена модель 172A. Изменения: хвостовое оперение и руль направления с обратной стреловидностью и крепления для поплавкового шасси.</td>\n","      <td>Модель 172А с другим хвостовым оперением,  креплениями для поплавкового шасси рулём направления с обратной стреловидностью появилась в 1960 году.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ...                                                                                                                                      OUTPUT:output\n","0           3  ...                                                                                14 декабря 1944 года рабочий посёлок Ички переименован в Советский.\n","1           4  ...                                                В 1960 году вышла модель 172А. Отличие в хвостовом оперении, в руле направления и в креплении шасси\n","2           5  ...                                                            В выпущенной в 1960 году модель имела изменения в хвостовом оперении и руле направления\n","3           6  ...                                          Изменения: в хвосте и руле направления с обратной стреловидностью и крепления для поплавкового шасси.\\r\\n\n","4           7  ...  Модель 172А с другим хвостовым оперением,  креплениями для поплавкового шасси рулём направления с обратной стреловидностью появилась в 1960 году.\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":77}]},{"cell_type":"markdown","metadata":{"id":"7TVfQtR56kVg"},"source":["## Text preprocess"]},{"cell_type":"markdown","metadata":{"id":"RJF5gS1Azdbn"},"source":["Группируем данные по INPUT:\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"htPsw-sIRr3b","executionInfo":{"status":"ok","timestamp":1616338408610,"user_tz":-180,"elapsed":644,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["df_grouped = df.groupby('INPUT:source' ).agg({'OUTPUT:output': '(SEP)'.join})\n","input_corpus = df_grouped.index.values\n","output_corpus = [output_text.split('(SEP)') for output_text in df_grouped['OUTPUT:output'].values]\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"M1CEOcVhSVux","executionInfo":{"status":"ok","timestamp":1616338409847,"user_tz":-180,"elapsed":680,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"b38bc877-d2d2-41c1-98da-d9f4d0bbc4fc"},"source":["df_grouped.head(5)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>OUTPUT:output</th>\n","    </tr>\n","    <tr>\n","      <th>INPUT:source</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1960 году была выпущена модель 172A. Изменения: хвостовое оперение и руль направления с обратной стреловидностью и крепления для поплавкового шасси.</th>\n","      <td>В 1960 году вышла модель 172А. Отличие в хвостовом оперении, в руле направления и в креплении шасси(SEP)В выпущенной в 1960 году модель имела изме...</td>\n","    </tr>\n","    <tr>\n","      <th>14 декабря 1944 года рабочий посёлок Ички был переименован в рабочий посёлок Советский, после чего поселковый совет стал называться Советским.</th>\n","      <td>14 декабря 1944 года рабочий посёлок Ички переименован в Советский.</td>\n","    </tr>\n","    <tr>\n","      <th>26 августа 2014 года Болдок принял участие в памятном матче Кубка Футбольной лиги против «Манчестер Юнайтед», в котором «донс» сенсационно обыграл команду Луи ван Гала со счётом 4:0.</th>\n","      <td>26 августа 2014 года Болдок выиграл футбольный матч Кубка лиги у команды Луи ван Гала со счётом 4:0(SEP)26 августа 2014 года Болдок принял участие...</td>\n","    </tr>\n","    <tr>\n","      <th>Armory — клиент с различными функциями для повышения безопасности, является надстройкой, работающей поверх bitcoind, однако использует собственный формат хранения секретного ключа.</th>\n","      <td>Armory - программа с различными функциями для повышения безопасности. Является дополнением, которое работает вместе с bitcoind, но использует свой...</td>\n","    </tr>\n","    <tr>\n","      <th>Concert for Diana (рус. Концерт для Дианы) — концерт памяти, организованный в честь Дианы, принцессы Уэльской.</th>\n","      <td>Concert for Diana - это концерт, посвящённый памяти принцессы Дианы Уэльской.(SEP)В честь Дианы, принцессы Уэльской ,организован концерт памяти Ди...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                OUTPUT:output\n","INPUT:source                                                                                                                                                                                                                                                                                                 \n"," 1960 году была выпущена модель 172A. Изменения: хвостовое оперение и руль направления с обратной стреловидностью и крепления для поплавкового шасси.   В 1960 году вышла модель 172А. Отличие в хвостовом оперении, в руле направления и в креплении шасси(SEP)В выпущенной в 1960 году модель имела изме...\n","14 декабря 1944 года рабочий посёлок Ички был переименован в рабочий посёлок Советский, после чего поселковый совет стал называться Советским.                                                                                            14 декабря 1944 года рабочий посёлок Ички переименован в Советский.\n","26 августа 2014 года Болдок принял участие в памятном матче Кубка Футбольной лиги против «Манчестер Юнайтед», в котором «донс» сенсационно обыграл ...  26 августа 2014 года Болдок выиграл футбольный матч Кубка лиги у команды Луи ван Гала со счётом 4:0(SEP)26 августа 2014 года Болдок принял участие...\n","Armory — клиент с различными функциями для повышения безопасности, является надстройкой, работающей поверх bitcoind, однако использует собственный ...  Armory - программа с различными функциями для повышения безопасности. Является дополнением, которое работает вместе с bitcoind, но использует свой...\n","Concert for Diana (рус. Концерт для Дианы) — концерт памяти, организованный в честь Дианы, принцессы Уэльской.                                          Concert for Diana - это концерт, посвящённый памяти принцессы Дианы Уэльской.(SEP)В честь Дианы, принцессы Уэльской ,организован концерт памяти Ди..."]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"aK8az3dJ6n2m","executionInfo":{"status":"ok","timestamp":1616338413425,"user_tz":-180,"elapsed":610,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["#@lru_cache(maxsize=32)\n","def text_preprocess(corpus):\n","    predictor = RNNMorphPredictor(language=\"ru\")\n","    new_corpus = []\n","    for sentence in tqdm_notebook(corpus, desc= 'preprocessing...'):\n","        sentence = ' '.join([predictor.predict([token.text])[0].normal_form \n","                             if token.text.isnumeric()==False else token.text \n","                             for token in list(tokenize(sentence))])\n","        new_corpus.append(sentence)\n","    return new_corpus\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"DUc2ZbF4Phpk","executionInfo":{"status":"ok","timestamp":1616338417419,"user_tz":-180,"elapsed":651,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["def dataframe_lemmatized(input_corpus, output_corpus):\n","    df_lemmatized = pd.DataFrame()\n","    input_text_lemmatized = text_preprocess(input_corpus)\n","    # returns list of lemmatized group of text which corresponds to one input text\n","    output_text_lemmatized = [text_preprocess(group) for group in output_corpus]\n","\n","    df_lemmatized['input'] = input_text_lemmatized \n","    df_lemmatized = pd.concat([df_lemmatized , pd.DataFrame(data = output_text_lemmatized, columns = ['output_1' , \n","                                                                                                      'output_2' , \n","                                                                                                      'output_3' , \n","                                                                                                      'output_4' , \n","                                                                                                      'output_5'])], axis=1)\n","    return df_lemmatized"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0E6-5ZtVR-dN"},"source":["Загружаем ранее лемматизированный текст:"]},{"cell_type":"code","metadata":{"id":"LQkS5YeAREt5","executionInfo":{"status":"ok","timestamp":1616339406114,"user_tz":-180,"elapsed":617,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["try:\n","    df_lemmatized = pd.read_csv(os.path.join(PATH,'lemmatized_text.csv'))\n","    df_lemmatized = df_lemmatized.fillna(0)  \n","except FileNotFoundError:\n","    df_lemmatized = dataframe_lemmatized(input_corpus, output_corpus)\n","    df_lemmatized.to_csv(os.path.join(PATH, 'lemmatized_text.csv'))\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":867},"id":"ASxs_kGRctI7","executionInfo":{"status":"ok","timestamp":1616339407169,"user_tz":-180,"elapsed":411,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"2977ce4c-1338-4420-80f2-4bfc8a7a4ddb"},"source":["df_lemmatized.head()"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>input</th>\n","      <th>output_1</th>\n","      <th>output_2</th>\n","      <th>output_3</th>\n","      <th>output_4</th>\n","      <th>output_5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1960 год быть выпущенный модель 172 a . изменение : хвостовой оперение и руль направление с обратный стреловидность и крепление для поплавковый ша...</td>\n","      <td>в 1960 год выйти модель 172 а . отличие в хвостовой оперение , в руль направление и в крепление шасси</td>\n","      <td>в выпущенный в 1960 год модель иметь изменение в хвостовой оперение и руль направление</td>\n","      <td>изменение : в хвост и руль направление с обратный стреловидность и крепление для поплавковый шасси .</td>\n","      <td>модель 172 а с другой хвостовой оперение , крепление для поплавковый шасси руль направление с обратный стреловидность появиться в 1960 год .</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>14 декабрь 1944 год рабочий посёлок ичка быть переименованный в рабочий посёлок советский , посол что поселковый совет стать называться советский .</td>\n","      <td>14 декабрь 1944 год рабочий посёлок ичка переименованный в советский .</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>26 август 2014 год болдок принять участие в памятный матч кубок футбольный лига против « манчестер юнайтед » , в который « донс » сенсационно обыг...</td>\n","      <td>26 август 2014 год болдок выиграть футбольный матч кубок лига у команда луи ван гала со счёт 4 : 0</td>\n","      <td>26 август 2014 год болдок принять участие в футбольный матч против « манчестер юнайтед » , где победить со счёт 4 : 0 .</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>armory — клиент с различный функция для повышение безопасность , являться надстройка , работающий поверх bitcoind , однако использовать собственны...</td>\n","      <td>armory - программа с различный функция для повышение безопасность . являться дополнение , который работать вместе с bitcoind , но использовать сво...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>concert for diana ( рус . концерт для диана ) — концерт память , организованный в честь диана , принцесса уэльский .</td>\n","      <td>concert for diana - это концерт , посвящённый память принцесса диана уэльский .</td>\n","      <td>в честь диана , принцесса уэльский , организованный концерт память диана .</td>\n","      <td>концерт для дианы- концентр память диана , принцесса уэльский .</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ... output_5\n","0           0  ...        0\n","1           1  ...        0\n","2           2  ...        0\n","3           3  ...        0\n","4           4  ...        0\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x21-Gif6CGup","executionInfo":{"status":"ok","timestamp":1616339410194,"user_tz":-180,"elapsed":613,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"06c27cc3-13a3-48fb-8c19-8a051a9dad57"},"source":["df_lemmatized.shape"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 7)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"JJ92mVLRctvQ"},"source":["## Matching"]},{"cell_type":"markdown","metadata":{"id":"3hBRIMZmFZDp"},"source":["Готовим данные для разметки и использования в обучении:"]},{"cell_type":"code","metadata":{"id":"pGZo67XoHhqL","executionInfo":{"status":"ok","timestamp":1616339411099,"user_tz":-180,"elapsed":456,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["input = df_grouped.index.values\n","output = output_corpus\n","input_lemma = df_lemmatized['input'].values\n","output_lemma = df_lemmatized[['output_1' , 'output_2' , 'output_3' , 'output_4' , 'output_5']].values\n"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wmq2FFlDf-jH"},"source":["Разбиваем датасет на тренировочную, валидационную и тестовую выборки"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wH28dl_bf9xl","executionInfo":{"status":"ok","timestamp":1616339412701,"user_tz":-180,"elapsed":645,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"b34f9d43-1206-42e0-8770-20df12c6382b"},"source":["ids = np.arange(1000)\n","train_id, valid_id = train_test_split(ids, train_size = 0.7, random_state = 42)\n","valid_id, test_id = train_test_split(valid_id, train_size = 0.5,  random_state = 42)\n","\n","\n","train_input, train_input_lemma, train_output_lemma = input[train_id], input_lemma[train_id] , output_lemma[train_id]\n","valid_input, valid_input_lemma, valid_output_lemma = input[valid_id], input_lemma[valid_id] , output_lemma[valid_id]\n","test_input, test_input_lemma, test_output_lemma = input[test_id], input_lemma[test_id] , output_lemma[test_id]\n","\n","print('Train data size:', train_input.shape , train_input_lemma.shape , train_output_lemma.shape )\n","print('Valid data size:', valid_input.shape , valid_input_lemma.shape , valid_output_lemma.shape )\n","print('Test data size:', test_input.shape , test_input_lemma.shape , test_output_lemma.shape )\n"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Train data size: (700,) (700,) (700, 5)\n","Valid data size: (150,) (150,) (150, 5)\n","Test data size: (150,) (150,) (150, 5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2HwMwLZ6gyTL"},"source":["Записываем токены и тэги в JSON-файл в BIO формате:"]},{"cell_type":"code","metadata":{"id":"aeyZIbzkMD17","executionInfo":{"status":"ok","timestamp":1616339862175,"user_tz":-180,"elapsed":633,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["#{\"tokens\": [\"APPLICATION\", \"and\", \"Affidavit\", \"for\", \"Search\", \"Warrant\", \"as\", \"to\", \"The\", \"Matter\", \"of\", \"the\", \"Search\", \"of\", \"9\", \"Granite\", \"Street\", \",\", \"#\", \"5\", \"(\", \"Attachments\", \":\", \"#\", \"1\", \"Affidavit\", \"of\", \"James\", \"Keczkemethy)(Belpedio\", \",\", \"Lisa\", \")\", \"(\", \"Entered\", \":\", \"12/15/2020\", \")\"], \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"L-MISC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}\n","\n","def matching(input, input_lemma, output_lemma, train_or_test):    \n","    with open(os.path.join(PATH,f'{train_or_test}.json') , 'w') as file:        \n","        for i, sentence in enumerate(input_lemma):\n","            # словарь для записи токенов и тэгов в json файл\n","            token_tag_dict = {}\n","            # список для записи тэгов\n","            tags = [] \n","            \n","            # сложный лемматизированный текст\n","            input_lemma_sentence = input_lemma[i].split(' ')  \n","\n","            # сложный исходный текст в виде списка токенов\n","            input_sentence = [token.text for token in list(tokenize(input[i]))]   \n","\n","            # упрощенные предложения, в списке через запятую\n","            output_lemma_sentence = ' '.join(output_lemma[i][output_lemma[i]!=0])\n","            \n","            # все варианты упрощенного предложения в виде списка токенов\n","            output_lemma_sentence = [token.text for token in list(tokenize(output_lemma_sentence))]\n","            \n","            # записываем исходный текст в json    \n","            token_tag_dict['tokens'] = input_sentence\n","          \n","            for token in input_lemma_sentence: \n","            # проверяем, если токен из исходного текста есть в упрощенном тексте,\n","                if token in output_lemma_sentence:\n","                  #  то ставим тэг I-YES\n","                    tags.append('I-YES')                              \n","                else:\n","                  # если нет токена в упрощенном тексте ставим O  \n","                    tags.append('O')                \n","            # записываем тэги в json\n","            token_tag_dict['tags'] = tags         \n","            # записываем все в файл\n","            json.dump(token_tag_dict , file, ensure_ascii = False)\n","            file.write('\\n')\n","    "],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-ETW075fb_Q","executionInfo":{"status":"ok","timestamp":1616339864811,"user_tz":-180,"elapsed":2112,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["# train 70% of data\n","matching(train_input, train_input_lemma, train_output_lemma, 'train')\n","\n","# valid 15% of data\n","matching(valid_input, valid_input_lemma, valid_output_lemma, 'valid')\n","\n","# test 15% of data\n","matching(test_input, test_input_lemma, test_output_lemma, 'test')\n"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CsCQpqyp0987"},"source":["## Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gO2j3UGRQ2dz","executionInfo":{"status":"ok","timestamp":1616340132724,"user_tz":-180,"elapsed":869,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"547be3c2-bc66-4326-989f-06f181a2ca36"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification\n","!wget \"https://github.com/huggingface/transformers/blob/master/examples/token-classification/run_ner.py\""],"execution_count":57,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/dialogue-rusimplification\n","--2021-03-21 15:22:13--  https://github.com/huggingface/transformers/blob/master/examples/token-classification/run_ner.py\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: ‘run_ner.py.1’\n","\n","run_ner.py.1            [ <=>                ] 261.40K  --.-KB/s    in 0.03s   \n","\n","2021-03-21 15:22:14 (8.04 MB/s) - ‘run_ner.py.1’ saved [267678]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HQJw-CI8Pz6Q","executionInfo":{"status":"ok","timestamp":1616339881630,"user_tz":-180,"elapsed":1723,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["!export MAX_LENGTH=128\n","!export BERT_MODEL=bert-base-multilingual-cased\n","!export OUTPUT_DIR=germeval-model\n","!export BATCH_SIZE=32\n","!export NUM_EPOCHS=3\n","!export SAVE_STEPS=750\n","!export SEED=1\n"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WeuS4TxKZDOd","executionInfo":{"status":"ok","timestamp":1616340420085,"user_tz":-180,"elapsed":269527,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"7700d9b2-1104-4142-aa0f-587a8da348ac"},"source":["!python ./run_ner.py \\\n","  --model_name_or_path bert-base-multilingual-cased \\\n","  --pad_to_max_length=True \\\n","  --train_file train.json \\\n","  --validation_file valid.json \\\n","  --test_file test.json \\\n","  --output_dir OUTPUT_DIR \\\n","  --do_train \\\n","  --do_eval \\\n","  --do_predict"],"execution_count":58,"outputs":[{"output_type":"stream","text":["2021-03-21 15:22:37.662774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","03/21/2021 15:22:38 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","03/21/2021 15:22:38 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=OUTPUT_DIR, overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=True, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/Mar21_15-22-38_87f64ee9eca0, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=OUTPUT_DIR, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=1)\n","03/21/2021 15:22:39 - WARNING - datasets.builder -   Using custom data configuration default-50626115ec56882e\n","Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-50626115ec56882e/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-50626115ec56882e/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.\n","[INFO|file_utils.py:1392] 2021-03-21 15:22:39,682 >> https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpv2t4tbf3\n","Downloading: 100% 625/625 [00:00<00:00, 721kB/s]\n","[INFO|file_utils.py:1396] 2021-03-21 15:22:39,886 >> storing https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","[INFO|file_utils.py:1399] 2021-03-21 15:22:39,886 >> creating metadata file for /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","[INFO|configuration_utils.py:468] 2021-03-21 15:22:39,886 >> loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","[INFO|configuration_utils.py:504] 2021-03-21 15:22:39,887 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"finetuning_task\": \"ner\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.5.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","[INFO|configuration_utils.py:468] 2021-03-21 15:22:40,097 >> loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","[INFO|configuration_utils.py:504] 2021-03-21 15:22:40,098 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.5.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","[INFO|file_utils.py:1392] 2021-03-21 15:22:40,321 >> https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpva_iprmz\n","Downloading: 100% 996k/996k [00:00<00:00, 2.59MB/s]\n","[INFO|file_utils.py:1396] 2021-03-21 15:22:40,920 >> storing https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n","[INFO|file_utils.py:1399] 2021-03-21 15:22:40,920 >> creating metadata file for /root/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n","[INFO|file_utils.py:1392] 2021-03-21 15:22:41,150 >> https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpevn_uiot\n","Downloading: 100% 1.96M/1.96M [00:00<00:00, 4.33MB/s]\n","[INFO|file_utils.py:1396] 2021-03-21 15:22:41,831 >> storing https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n","[INFO|file_utils.py:1399] 2021-03-21 15:22:41,832 >> creating metadata file for /root/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n","[INFO|file_utils.py:1392] 2021-03-21 15:22:42,455 >> https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp3stv07zf\n","Downloading: 100% 29.0/29.0 [00:00<00:00, 36.4kB/s]\n","[INFO|file_utils.py:1396] 2021-03-21 15:22:42,658 >> storing https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","[INFO|file_utils.py:1399] 2021-03-21 15:22:42,658 >> creating metadata file for /root/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","[INFO|tokenization_utils_base.py:1702] 2021-03-21 15:22:42,659 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n","[INFO|tokenization_utils_base.py:1702] 2021-03-21 15:22:42,659 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n","[INFO|tokenization_utils_base.py:1702] 2021-03-21 15:22:42,659 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1702] 2021-03-21 15:22:42,659 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1702] 2021-03-21 15:22:42,659 >> loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","[INFO|file_utils.py:1392] 2021-03-21 15:22:42,976 >> https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpnzhufc7t\n","Downloading: 100% 714M/714M [00:11<00:00, 61.2MB/s]\n","[INFO|file_utils.py:1396] 2021-03-21 15:22:54,717 >> storing https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n","[INFO|file_utils.py:1399] 2021-03-21 15:22:54,717 >> creating metadata file for /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n","[INFO|modeling_utils.py:1051] 2021-03-21 15:22:54,718 >> loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n","[WARNING|modeling_utils.py:1159] 2021-03-21 15:23:00,536 >> Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1170] 2021-03-21 15:23:00,536 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 1/1 [00:00<00:00,  3.39ba/s]\n","100% 1/1 [00:00<00:00, 17.09ba/s]\n","100% 1/1 [00:00<00:00, 17.13ba/s]\n","Downloading: 4.95kB [00:00, 4.36MB/s]       \n","[INFO|trainer.py:485] 2021-03-21 15:23:12,717 >> The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens.\n","[INFO|trainer.py:485] 2021-03-21 15:23:12,718 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens.\n","[INFO|trainer.py:975] 2021-03-21 15:23:12,904 >> ***** Running training *****\n","[INFO|trainer.py:976] 2021-03-21 15:23:12,904 >>   Num examples = 700\n","[INFO|trainer.py:977] 2021-03-21 15:23:12,904 >>   Num Epochs = 3\n","[INFO|trainer.py:978] 2021-03-21 15:23:12,904 >>   Instantaneous batch size per device = 8\n","[INFO|trainer.py:979] 2021-03-21 15:23:12,904 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:980] 2021-03-21 15:23:12,904 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:981] 2021-03-21 15:23:12,904 >>   Total optimization steps = 264\n","100% 264/264 [03:31<00:00,  1.42it/s][INFO|trainer.py:1158] 2021-03-21 15:26:44,615 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 211.7115, 'train_samples_per_second': 1.247, 'epoch': 3.0}\n","100% 264/264 [03:31<00:00,  1.25it/s]\n","[INFO|trainer.py:1587] 2021-03-21 15:26:44,812 >> Saving model checkpoint to OUTPUT_DIR\n","[INFO|configuration_utils.py:314] 2021-03-21 15:26:44,829 >> Configuration saved in OUTPUT_DIR/config.json\n","[INFO|modeling_utils.py:837] 2021-03-21 15:26:47,914 >> Model weights saved in OUTPUT_DIR/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:1896] 2021-03-21 15:26:47,922 >> tokenizer config file saved in OUTPUT_DIR/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:1902] 2021-03-21 15:26:47,926 >> Special tokens file saved in OUTPUT_DIR/special_tokens_map.json\n","[INFO|trainer_pt_utils.py:656] 2021-03-21 15:26:48,137 >> ***** train metrics *****\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   epoch                      =      3.0\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   init_mem_cpu_alloc_delta   =      0MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   init_mem_cpu_peaked_delta  =      0MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   init_mem_gpu_alloc_delta   =    676MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   init_mem_gpu_peaked_delta  =      0MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   train_mem_cpu_alloc_delta  =      0MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   train_mem_cpu_peaked_delta =      0MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   train_mem_gpu_alloc_delta  =   2095MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   train_mem_gpu_peaked_delta =   6202MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   train_runtime              = 211.7115\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   train_samples              =      700\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:48,138 >>   train_samples_per_second   =    1.247\n","03/21/2021 15:26:48 - INFO - __main__ -   *** Evaluate ***\n","[INFO|trainer.py:1804] 2021-03-21 15:26:48,266 >> ***** Running Evaluation *****\n","[INFO|trainer.py:1805] 2021-03-21 15:26:48,266 >>   Num examples = 150\n","[INFO|trainer.py:1806] 2021-03-21 15:26:48,266 >>   Batch size = 8\n","100% 19/19 [00:05<00:00,  3.58it/s]\n","[INFO|trainer_pt_utils.py:656] 2021-03-21 15:26:54,015 >> ***** eval metrics *****\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,015 >>   epoch                     =    3.0\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,015 >>   eval_accuracy             =  0.784\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_f1                   = 0.1869\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_loss                 = 0.5502\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_mem_cpu_alloc_delta  =    1MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_mem_cpu_peaked_delta =    1MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_mem_gpu_alloc_delta  =    0MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_mem_gpu_peaked_delta =  277MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_precision            = 0.2076\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_recall               = 0.1699\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_runtime              = 5.6411\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_samples              =    150\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:26:54,016 >>   eval_samples_per_second   = 26.591\n","03/21/2021 15:26:54 - INFO - __main__ -   *** Predict ***\n","[INFO|trainer.py:485] 2021-03-21 15:26:54,115 >> The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens.\n","[INFO|trainer.py:1804] 2021-03-21 15:26:54,117 >> ***** Running Prediction *****\n","[INFO|trainer.py:1805] 2021-03-21 15:26:54,117 >>   Num examples = 150\n","[INFO|trainer.py:1806] 2021-03-21 15:26:54,117 >>   Batch size = 8\n","100% 19/19 [00:05<00:00,  3.73it/s][INFO|trainer_pt_utils.py:656] 2021-03-21 15:27:00,075 >> ***** test metrics *****\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,075 >>   eval_accuracy             = 0.7529\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,075 >>   eval_f1                   = 0.1778\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,075 >>   eval_loss                 = 0.6078\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,076 >>   eval_precision            = 0.1909\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,076 >>   eval_recall               = 0.1664\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,076 >>   eval_runtime              = 5.7725\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,076 >>   eval_samples_per_second   = 25.985\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,076 >>   test_mem_cpu_alloc_delta  =    1MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,076 >>   test_mem_cpu_peaked_delta =    1MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,076 >>   test_mem_gpu_alloc_delta  =    0MB\n","[INFO|trainer_pt_utils.py:661] 2021-03-21 15:27:00,076 >>   test_mem_gpu_peaked_delta =  277MB\n","100% 19/19 [00:05<00:00,  3.33it/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QZ2UJ-49MEqK"},"source":["## Predictions"]},{"cell_type":"code","metadata":{"id":"FeAQpiKlgVf-","executionInfo":{"status":"ok","timestamp":1616340577470,"user_tz":-180,"elapsed":626,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["def tag_to_text(path_to_file): \n","    simplified = []\n","    with open(path_to_file, 'rb') as file:\n","        for i,row in enumerate(file):\n","            # проходим по файлу и записываем токены в в список.\n","            tags = np.array(str(row)[2:-3].split(' '))\n","            # в переменную записываем id токенов с тэгом I-YES\n","            I_YES_id, = np.where(tags=='I-YES')\n","            \n","            # список токенов в исходном тексте в тестовом наборе\n","            test_tokens_list = np.array([token.text for token in list(tokenize(test_input[i]))])\n","            \n","            # упрощеное предложение в виде списка токенов \n","            test_simple = test_tokens_list[I_YES_id]\n","            # упрощенное предложение в виде строки\n","            test_simple = ' '.join(test_simple.tolist())\n","\n","            # предложение записываем в список\n","            simplified.append(test_simple)\n","    return simplified"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"IUQREu8usx8C","executionInfo":{"status":"ok","timestamp":1616340579128,"user_tz":-180,"elapsed":633,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["simplified = tag_to_text('./OUTPUT_DIR/test_predictions.txt')"],"execution_count":62,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eBNB3l5QvvZM"},"source":["## Evaluation"]},{"cell_type":"markdown","metadata":{"id":"Z_G8G4yav9mF"},"source":["Данные для оценкки модели"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VKZk2sS_xCcD","executionInfo":{"status":"ok","timestamp":1616340585176,"user_tz":-180,"elapsed":654,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"41efe889-6173-4857-db17-c317b2f812de"},"source":["# исходные предложения в виде списка\n","input_sents = test_input.tolist()\n","# упрощенные предложения в виде списка списков.\n","output_sents = np.array(output_corpus)[test_id].tolist()\n"],"execution_count":63,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  after removing the cwd from sys.path.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"mgXxWpHmaTXg"},"source":["Оцениваем модель по метрике SARI"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1aNXfBu1oIXX","executionInfo":{"status":"ok","timestamp":1616340685264,"user_tz":-180,"elapsed":668,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"9c19e1b6-93c2-4780-d06e-d119527a8192"},"source":["from easse.sari import corpus_sari\n","\n","corpus_sari(orig_sents=input_sents,  \n","            sys_sents=simplified, \n","            refs_sents= output_sents)"],"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["24.009557417342943"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"markdown","metadata":{"id":"7c3Z5bjDabMY"},"source":["Для визуальной оценки результатов запишем данные в датафрейм:"]},{"cell_type":"code","metadata":{"id":"ZxcEmNdhaaap","executionInfo":{"status":"ok","timestamp":1616340804585,"user_tz":-180,"elapsed":563,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}}},"source":["df_result = pd.DataFrame({'input':input_sents , 'output':output_sents ,'simplified': simplified})"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"id":"gNMSOwPHvbih","executionInfo":{"status":"ok","timestamp":1616341111020,"user_tz":-180,"elapsed":586,"user":{"displayName":"Ivan Oleynikov","photoUrl":"","userId":"09159091653969316809"}},"outputId":"d0d8baa8-762e-4ee8-f271-3cb708c6d02d"},"source":["df_result.head(5)"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>output</th>\n","      <th>simplified</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Одним из главных событий в творческой биографии Высоцкого стала работа над ролью Гамлета в Театре на Таганке.</td>\n","      <td>[Роль Гамлета является одной из главных в биографии Высоцкого., Важнейшая роль Высоцкого - Гамлет в Театре на Таганке., Главное событие в биографи...</td>\n","      <td>в биографии Высоцкого работа над ролью Гамлета в Театре на Таганке .</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>С первого удара Линдланд нанес Емельяненко рассечение над правым глазом и вошёл в клинч в попытке перевести бой в партер.</td>\n","      <td>[Лингдланд дал Емельяненко в глаз, а затем применил запрещённый приём., Линдланд попытался перевести бой в партер с Емельяненко., Линдланд в бою п...</td>\n","      <td>С первого удара Линдланд нанес Емельяненко рассечение над правым глазом и вошёл в клинч в перевести бой в партер .</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Чтобы иметь возможность показать картину возможно большей зрительской аудитории, создатели фильма значительно смягчили на экране любовный контекст...</td>\n","      <td>[В фильме меньше любовных сцен, чем в книге. Это сделано для того, чтобы показать его большому количеству зрителей., Создатели фильма смягчили люб...</td>\n","      <td>показать картину большей , создатели фильма смягчили на любовный книги .</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>В своём докладе Немцов отмечает непрозрачность процедур при строительстве олимпийских объектов, отсутствие общественного контроля, закрытость инфо...</td>\n","      <td>[В докладе Немцова отмечено о грубых нарушениях и скрытости точной информации при строительстве олимпийских объектов, В своём докладе Немцов отмеч...</td>\n","      <td>В своём докладе Немцов непрозрачность процедур при строительстве олимпийских объектов , отсутствие общественного контроля , закрытость информации ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Описанные Джимом Корбеттом, известным охотником на тигров, подобные случаи показывают, насколько драматичными и кровопролитными могут быть столкно...</td>\n","      <td>[Охотник на тигров Корбетт описывал подобные случае столкновения тигра с людьми как драматичные и кровопролитные]</td>\n","      <td>Описанные Джимом Корбеттом , охотником на тигров , случаи показывают , и кровопролитными могут быть столкновения тигра с людьми .</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                   input  ...                                                                                                                                             simplified\n","0                                          Одним из главных событий в творческой биографии Высоцкого стала работа над ролью Гамлета в Театре на Таганке.  ...                                                                                   в биографии Высоцкого работа над ролью Гамлета в Театре на Таганке .\n","1                              С первого удара Линдланд нанес Емельяненко рассечение над правым глазом и вошёл в клинч в попытке перевести бой в партер.  ...                                     С первого удара Линдланд нанес Емельяненко рассечение над правым глазом и вошёл в клинч в перевести бой в партер .\n","2  Чтобы иметь возможность показать картину возможно большей зрительской аудитории, создатели фильма значительно смягчили на экране любовный контекст...  ...                                                                               показать картину большей , создатели фильма смягчили на любовный книги .\n","3  В своём докладе Немцов отмечает непрозрачность процедур при строительстве олимпийских объектов, отсутствие общественного контроля, закрытость инфо...  ...  В своём докладе Немцов непрозрачность процедур при строительстве олимпийских объектов , отсутствие общественного контроля , закрытость информации ...\n","4  Описанные Джимом Корбеттом, известным охотником на тигров, подобные случаи показывают, насколько драматичными и кровопролитными могут быть столкно...  ...                      Описанные Джимом Корбеттом , охотником на тигров , случаи показывают , и кровопролитными могут быть столкновения тигра с людьми .\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"lKtJ3KWNT5zM"},"source":[""],"execution_count":null,"outputs":[]}]}